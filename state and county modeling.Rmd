---
title: "Modeling"
author: "Delila Medlin"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("C:/Users/delil/Desktop/Fall 2024/Research 2024/Data/Preliminary_modeling/drought_functions.R")
```

Loading in the pdsi data
```{r}
pdsi <- rast("agg_met_pdsi_1979_CurrentYear_CONUS.nc")
```

Pima County, AZ
```{r}
set.seed(1)
drought.az.pima <- read.csv("USDM-Pima.csv")
pima <- clean.county.data("Arizona", "Pima", pdsi, drought.az.pima)

# model with single training and testing set
pima.train <- pima %>% sample_frac(0.80)
pima.test <- anti_join(pima, pima.train, by = 'id')

pima.rf.fit <- randomForest(WeightedAverage ~ ., 
             data = pima.train, 
             importance = TRUE)
summary(pima.rf.fit)
pima.preds <- predict(pima.rf.fit, pima.test)
RMSE(pima.test$WeightedAverage, pima.preds)

# modeling using cross validation
ctrl <- trainControl(method = "cv", number = 10)
pima.cv.rf.fit <- train(WeightedAverage ~ ., 
                   data = pima, 
                   method = "rf", 
                   trControl = ctrl)

print(pima.cv.rf.fit)


quick.rf(pima)
```

Lewis County, WV
```{r}
set.seed(1)
drought.lewis <- read.csv("USDM-54041-Lewis-WV.csv")
lewis <- clean.county.data("West Virginia", "Lewis", pdsi, drought.lewis)

# model with single training and testing set
lewis.train <- lewis %>% sample_frac(0.80)
lewis.test <- anti_join(lewis, lewis.train, by = 'id')

lewis.rf.fit <- randomForest(WeightedAverage ~ ., 
             data = lewis.train, 
             importance = TRUE)

lewis.preds <- predict(lewis.rf.fit, lewis.test)
RMSE(lewis.test$WeightedAverage, lewis.preds) # 0.3089867

# put this exact modeling structure into a function
quick.rf(lewis)

```
Cascade County, MT
```{r}
drought.cascade <- read.csv("USDM-30013-Cascade-MT.csv")
cascade <- clean.county.data("Montana", "Cascade", pdsi, drought.cascade)

quick.rf(cascade)
```

Grady County, OK
```{r}
drought.grady <- read.csv("USDM-40051-Grady-OK.csv")
grady <- clean.county.data("Oklahoma", "Grady", pdsi, drought.grady)

quick.rf(grady)
```

Hennepin County, MN
```{r}
drought.henn <- read.csv("USDM-27053-Hennepin-MN.csv")
henn <- clean.county.data("Minnesota", "Hennepin", pdsi, drought.henn)

quick.rf(henn)
```

Testing Arizona as a whole state: Fips Codes 
4001-Apache
4003-Cochise
4005-Cocinino
4007-Gila
4009-Graham
4011-Greenlee
4012-La Paz
4013-Maricopa
4015-Mohave
4017-Navajo
4019-Pima
4021-Pinal
4023-Santa Cruz
4025-Yavapai

What I worked on shortly after Meeting on 1/22 as a brute fore attempt at getting all of the county data for AZ.  
```{r}
set.seed(1)

# initialize list with all of the county fips codes
az.fips <- c("04001", "04003", "04005", "04007", "04009", 
             "04011", "04012", "04013", "04015", "04017", 
             "04019", "04021", "04023", "04025", "04027")
# Initialize a list with all of the names of arizona counties
az.counties <- c("Apache", "Cochise", "Coconino", "Gila", 
            "Graham", "Greenlee", "La Paz", "Maricopa",
            "Mohave", "Navajo", "Pima", "Pinal", 
            "Santa Cruz", "Yavapai", "Yuma")
# create list of az data to store
AZ.data <- list()

# loop through each county 
for (index in seq_along(az.counties)){
  county.name <- az.counties[index]
  fips <- az.fips[index]
  
  # get the file name 
  file.name <- paste0("C:/Users/delil/Desktop/Fall 2024/Research 2024/Data/Preliminary_modeling/AZ_Counties/USDM-", fips, ".csv")
  
  # read in the data
  drought.data <- read.csv(file.name)
  
  # process and save to list 
  AZ.data[[county.name]] <- clean.county.data("Arizona", county.name, pdsi, drought.data)
}

#head(AZ.data)
```

```{r}
set.seed(1)

# Loop through each county in AZ.data
for (county_name in names(AZ.data)) {
  # Extract the data for the county
  county_data <- AZ.data[["Pima"]]
  
  # split into training and testing 
  train <- county_data %>% sample_frac(0.80)
  test <- anti_join(county_data, train, by = 'id')
  
  # save the testing weighted average values for comparison
  test_y <- test %>% select(WeightedAverage)
  
  # build model
  rf.fit <- randomForest(WeightedAverage ~ ., 
                               data = train, 
                               importance = TRUE)
  
  # predict and find RMSE
  preds <- predict(rf.fit, test)
  
  # Predict on testing set
  predictions <- predict(rf_model, newdata = test_x)
  
  
  # code from chatgpt from here on 
  
  # Store results
  results[[county_name]] <- data.frame(
    actual = test_y,
    predicted = predictions
  )
}

# Combine results for all counties into a single data frame
combined_results <- do.call(rbind, lapply(names(results), function(county_name) {
  cbind(
    county = county_name,
    results[[county_name]]
  )
}))

# Display combined results
head(combined_results)

```

